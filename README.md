# COVID-19 Data Processing
This repository contains the steps and code for processing COVID-19 data using AWS services.

## Task 1: Data Ingestion and Table Creation  
1. Create an S3 bucket named "covid19vijay".  
2. Upload the dataset to the S3 bucket.  
3. Use the AWS CLI to create a Glue database named "covid19vijay".  
4. Create two Glue crawlers: csv-crawler and json-crawler.  
5. Start the crawlers to create tables for the data in the S3 bucket.  
6. Verified data in the tables using the Athena query editor.

![Glue commands](https://github.com/VjKhatri/ml_incubator/blob/develop/Glue%20commands.JPG) 
![Data in S3](https://github.com/VjKhatri/ml_incubator/blob/develop/Data%20in%20S3.JPG)
![Data in athena](https://github.com/VjKhatri/ml_incubator/blob/develop/Data%20thorugh%20athena.JPG)


## Task 2: Data Transformation and Analysis
1. Created a Glue job to convert the CSV data into Parquet format.  
2. Created a crawler to scan the Parquet file generated by the Glue job.  
3. Start the crawler using the AWS CLI.  
4. Verified data using Athena.  

   
### Example Queries

#### Retrieve the top 5 states with the highest number of deaths:

`SELECT state, death FROM states_info ORDER BY death DESC LIMIT 5;`  


#### Get the date and the number of positive cases for the day with the highest number of positive cases in the US:  


`SELECT date, positive FROM us_daily ORDER BY positive DESC LIMIT 1;`


##### Enjoy exploring the COVID-19 data!
